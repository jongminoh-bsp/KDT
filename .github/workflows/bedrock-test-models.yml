name: 🤖 Test Different Claude Models

on:
  workflow_dispatch:
  push:
    branches: [dev]
    paths: ['test_app/**']

jobs:
  test-models:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    - name: Install boto3
      run: pip install boto3>=1.34.0
    
    - name: Test Multiple Claude Models
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-east-1
      run: |
        python3 << 'EOF'
        import boto3
        import json
        
        client = boto3.client('bedrock-runtime', region_name='us-east-1')
        
        # 테스트할 모델들 (활성화된 것들)
        models_to_test = [
            'anthropic.claude-3-sonnet-20240229-v1:0',  # Claude 3 Sonnet
            'anthropic.claude-3-haiku-20240307-v1:0',   # Claude 3 Haiku  
            'anthropic.claude-3-5-sonnet-20240620-v1:0' # Claude 3.5 Sonnet
        ]
        
        for model_id in models_to_test:
            try:
                print(f"\n🤖 Testing model: {model_id}")
                
                response = client.invoke_model(
                    modelId=model_id,
                    body=json.dumps({
                        "anthropic_version": "bedrock-2023-05-31",
                        "max_tokens": 200,
                        "messages": [{
                            "role": "user", 
                            "content": "Hello! Can you analyze a Node.js Express app with MongoDB? Just say 'Yes, I can analyze it' if you're working."
                        }]
                    })
                )
                
                result = json.loads(response['body'].read())
                ai_response = result['content'][0]['text']
                
                print(f"✅ SUCCESS with {model_id}!")
                print(f"Response: {ai_response}")
                print("=" * 50)
                
                # 첫 번째 성공한 모델로 실제 분석
                print(f"\n🎉 Using {model_id} for real analysis...")
                
                analysis_response = client.invoke_model(
                    modelId=model_id,
                    body=json.dumps({
                        "anthropic_version": "bedrock-2023-05-31",
                        "max_tokens": 400,
                        "messages": [{
                            "role": "user", 
                            "content": "Analyze this Node.js application: Express server with MongoDB and Redis dependencies. Recommend AWS infrastructure in JSON format with: framework, database_type, cache_type, memory_gb, replicas."
                        }]
                    })
                )
                
                analysis_result = json.loads(analysis_response['body'].read())
                analysis_text = analysis_result['content'][0]['text']
                
                print("\n🚀 REAL AMAZON BEDROCK CLAUDE ANALYSIS:")
                print("=" * 70)
                print(analysis_text)
                print("=" * 70)
                print("\n✅ Amazon Bedrock is working in GitHub Actions!")
                print("🤖 This is real AI analysis from Claude!")
                break
                
            except Exception as e:
                print(f"❌ Failed with {model_id}: {e}")
                continue
        else:
            print("❌ All models failed")
            exit(1)
        EOF
