name: â˜¸ï¸ Phase 2 - Application Deployment

on:
  pull_request:
    types: [closed]
    branches: [dev]
    paths: ['k8s/**']

env:
  AWS_REGION: ap-northeast-2

jobs:
  # Phase 2: ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
  deploy-application:
    if: github.event.pull_request.merged == true && contains(github.event.pull_request.labels.*.name, 'phase-2')
    runs-on: ubuntu-latest
    
    permissions:
      id-token: write
      contents: read
      pull-requests: write
      issues: write
    
    steps:
    - name: ğŸ“¥ Checkout Code
      uses: actions/checkout@v4
    
    - name: ğŸ”‘ Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
        aws-region: ${{ env.AWS_REGION }}
        role-session-name: GitHubActions-Phase2-Application
    
    - name: ğŸ” Find EKS Cluster
      id: cluster
      run: |
        # EKS í´ëŸ¬ìŠ¤í„° ì°¾ê¸° (skyline ë˜ëŠ” dev íŒ¨í„´)
        CLUSTER_NAME=$(aws eks list-clusters --region ${{ env.AWS_REGION }} --query 'clusters[?contains(@, `skyline`) || contains(@, `dev`)]' --output text | head -1)
        
        if [ -z "$CLUSTER_NAME" ]; then
          echo "âŒ No EKS cluster found"
          exit 1
        fi
        
        echo "âœ… Found EKS cluster: $CLUSTER_NAME"
        echo "cluster_name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
    
    - name: âš™ï¸ Configure kubectl
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ steps.cluster.outputs.cluster_name }}
        kubectl version --client
        kubectl get nodes
        echo "âœ… kubectl configured for EKS cluster"
    
    - name: ğŸ“¦ Deploy Application to EKS
      run: |
        echo "ğŸ“¦ Deploying application to EKS cluster..."
        
        # K8s ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì ìš© (ìˆœì„œëŒ€ë¡œ)
        if [ -d "k8s" ]; then
          echo "âœ… Found k8s manifests directory"
          
          # 1. Namespace ë¨¼ì €
          if [ -f "k8s/namespace.yaml" ]; then
            kubectl apply -f k8s/namespace.yaml
            echo "âœ… Namespace created"
          fi
          
          # 2. ConfigMapê³¼ Secret
          if [ -f "k8s/configmap.yaml" ]; then
            kubectl apply -f k8s/configmap.yaml
            echo "âœ… ConfigMap applied"
          fi
          
          if [ -f "k8s/secret.yaml" ]; then
            kubectl apply -f k8s/secret.yaml
            echo "âœ… Secret applied"
          fi
          
          # 3. Deploymentì™€ Service
          if [ -f "k8s/deployment.yaml" ]; then
            kubectl apply -f k8s/deployment.yaml
            echo "âœ… Deployment applied"
          fi
          
          if [ -f "k8s/service.yaml" ]; then
            kubectl apply -f k8s/service.yaml
            echo "âœ… Service applied"
          fi
          
          # 4. Ingress
          if [ -f "k8s/ingress.yaml" ]; then
            kubectl apply -f k8s/ingress.yaml
            echo "âœ… Ingress applied"
          fi
          
          # 5. HPA (ìˆëŠ” ê²½ìš°)
          if [ -f "k8s/hpa.yaml" ]; then
            kubectl apply -f k8s/hpa.yaml
            echo "âœ… HPA applied"
          fi
          
        else
          echo "âŒ No k8s directory found"
          exit 1
        fi
    
    - name: â³ Wait for Application Ready
      run: |
        echo "â³ Waiting for application deployment..."
        
        # Deploymentê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        kubectl wait --for=condition=available --timeout=300s deployment/skyline-deployment -n skyline || true
        
        # Pod ìƒíƒœ í™•ì¸
        kubectl get pods -n skyline -l app=skyline
        
        echo "âœ… Application deployment status checked"
    
    - name: ğŸ” Verify Deployment
      id: verify
      run: |
        echo "ğŸ” Verifying application deployment..."
        
        # ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸
        kubectl get all -n skyline
        
        # Ingress URL ê°€ì ¸ì˜¤ê¸°
        INGRESS_HOST=$(kubectl get ingress skyline-ingress -n skyline -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "Pending...")
        echo "ingress_host=$INGRESS_HOST" >> $GITHUB_OUTPUT
        
        # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        SERVICE_STATUS=$(kubectl get service skyline-service -n skyline -o jsonpath='{.status}' 2>/dev/null || echo "Not found")
        
        echo "ğŸŒ Application URL: https://www.greenbespinglobal.store"
        echo "ğŸ”— Load Balancer: $INGRESS_HOST"
    
    - name: ğŸ“Š Deployment Summary
      run: |
        echo "## ğŸ‰ Phase 2 Application Deployment Complete!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ğŸ“¦ Deployed Application" >> $GITHUB_STEP_SUMMARY
        echo "- **EKS Cluster**: ${{ steps.cluster.outputs.cluster_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Namespace**: skyline" >> $GITHUB_STEP_SUMMARY
        echo "- **Deployment**: skyline-deployment" >> $GITHUB_STEP_SUMMARY
        echo "- **Service**: skyline-service" >> $GITHUB_STEP_SUMMARY
        echo "- **Ingress**: skyline-ingress" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ğŸŒ Access Information" >> $GITHUB_STEP_SUMMARY
        echo "- **Application URL**: https://www.greenbespinglobal.store" >> $GITHUB_STEP_SUMMARY
        echo "- **Health Check**: https://www.greenbespinglobal.store/health" >> $GITHUB_STEP_SUMMARY
        echo "- **Load Balancer**: ${{ steps.verify.outputs.ingress_host }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ğŸ“‹ Resource Status" >> $GITHUB_STEP_SUMMARY
        echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        kubectl get all -n skyline >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "Status check failed" >> $GITHUB_STEP_SUMMARY
        echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**ğŸš€ Application is now live!**" >> $GITHUB_STEP_SUMMARY
    
    - name: ğŸ’¬ Phase 2 Success Comment
      uses: actions/github-script@v7
      with:
        script: |
          const comment = `## ğŸ‰ Phase 2 Application Deployment Complete!
          
          **Deployment Time**: ${new Date().toISOString()}
          **EKS Cluster**: ${{ steps.cluster.outputs.cluster_name }}
          **Application Status**: âœ… Live
          
          ### ğŸš€ Application Access
          - **Primary URL**: https://www.greenbespinglobal.store
          - **Health Check**: https://www.greenbespinglobal.store/health
          - **Load Balancer**: ${{ steps.verify.outputs.ingress_host }}
          
          ### ğŸ“¦ Deployed Resources
          - âœ… **Namespace**: skyline (application isolation)
          - âœ… **Deployment**: 3 replicas with health checks
          - âœ… **Service**: Load balancing configured
          - âœ… **Ingress**: ALB with SSL termination
          - âœ… **ConfigMap**: Application configuration
          - âœ… **Secret**: Database credentials
          - âœ… **HPA**: Auto-scaling enabled
          
          ### ğŸ¯ Complete Pipeline Success!
          
          **Phase 1**: âœ… AWS Infrastructure deployed
          **Phase 2**: âœ… Application deployed to EKS
          
          ### ğŸ”— Management Commands
          \`\`\`bash
          # Connect to EKS cluster
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ steps.cluster.outputs.cluster_name }}
          
          # Check application status
          kubectl get all -n skyline
          
          # View application logs
          kubectl logs -f deployment/skyline-deployment -n skyline
          
          # Scale application
          kubectl scale deployment skyline-deployment --replicas=5 -n skyline
          \`\`\`
          
          **ğŸ‰ AI-Driven DevOps Pipeline Complete! Application is live!** ğŸš€`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
    
    - name: ğŸ·ï¸ Add Phase 2 Complete Label
      uses: actions/github-script@v7
      with:
        script: |
          github.rest.issues.addLabels({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: ['âœ… phase-2-complete', 'application-live', 'ğŸš€ pipeline-complete']
          });

  # Phase 2 ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
  rollback-on-failure:
    if: failure()
    runs-on: ubuntu-latest
    needs: deploy-application
    
    steps:
    - name: ğŸ”„ Rollback Application
      run: |
        echo "ğŸ”„ Rolling back Phase 2 application deployment..."
        
        # AWS ì„¤ì •
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name $(aws eks list-clusters --region ${{ env.AWS_REGION }} --query 'clusters[0]' --output text)
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡¤ë°±
        kubectl rollout undo deployment/skyline-deployment -n skyline 2>/dev/null || echo "No previous deployment to rollback"
        
        echo "âœ… Rollback completed"
    
    - name: ğŸš¨ Phase 2 Failure Notification
      uses: actions/github-script@v7
      with:
        script: |
          const comment = `## ğŸš¨ Phase 2 Application Deployment Failed
          
          **Failure Time**: ${new Date().toISOString()}
          **Phase**: Application Deployment (Phase 2)
          
          ### ğŸ” Troubleshooting
          1. Check [workflow logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          2. Verify EKS cluster is healthy
          3. Check Kubernetes manifests syntax
          4. Verify Docker image availability
          5. Check resource quotas and limits
          
          ### ğŸ”„ Recovery Actions
          - Application rollback attempted
          - Infrastructure (Phase 1) remains intact
          - Can retry Phase 2 deployment
          
          **Infrastructure is still available for retry.**`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
