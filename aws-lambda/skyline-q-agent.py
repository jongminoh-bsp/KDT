import json
import boto3
import os
import requests
from datetime import datetime

def lambda_handler(event, context):
    """
    Amazon Q Agent Lambda Function
    """
    
    print("ü§ñ Amazon Q Agent Lambda started")
    print(f"Event: {json.dumps(event, indent=2)}")
    
    repository = event.get('repository', 'KDT')
    branch = event.get('branch', 'dev')
    commit = event.get('commit', 'unknown')
    app_path = event.get('app_path', 'app/')
    
    try:
        # Step 1: Amazon Q AI Analysis
        ai_result = run_amazon_q_analysis(app_path)
        
        # Step 2: Generate Infrastructure Code
        infra_result = generate_infrastructure_code(ai_result)
        
        # Step 3: Generate Deployment Config
        deploy_result = generate_deployment_config(ai_result)
        
        # Step 4: Save to S3
        s3_results = save_results_to_s3(repository, branch, commit, {
            'ai_analysis': ai_result,
            'infrastructure': infra_result,
            'deployment': deploy_result,
            'timestamp': datetime.utcnow().isoformat()
        })
        
        # Step 5: Create GitHub PR with generated files
        pr_result = create_github_pr_with_generated_files(
            repository, branch, commit, ai_result, infra_result, deploy_result
        )
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'Amazon Q Agent completed successfully',
                'ai_analysis': ai_result,
                'files_generated': True,
                'github_pr_created': pr_result.get('success', False),
                'pr_url': pr_result.get('pr_url', 'N/A')
            })
        }
        
    except Exception as e:
        print(f"‚ùå Amazon Q Agent failed: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }

def run_amazon_q_analysis(app_path):
    """Run Amazon Q AI analysis"""
    print("ü§ñ Running Amazon Q AI analysis...")
    
    bedrock = boto3.client('bedrock-runtime', region_name='ap-northeast-2')
    
    try:
        response = bedrock.invoke_model(
            modelId='anthropic.claude-3-haiku-20240307-v1:0',
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 200,
                "messages": [{
                    "role": "user",
                    "content": "Analyze Spring Boot airline app. Recommend: memory=2Gi, cpu=1000m, replicas=3, database=mysql, instance_type=t3.medium"
                }]
            })
        )
        
        result = json.loads(response['body'].read())
        ai_response = result['content'][0]['text']
        
        print("üéâ Amazon Q Analysis:", ai_response)
        
        return {
            'status': 'success',
            'recommendations': {
                'memory': '2Gi',
                'cpu': '1000m',
                'replicas': 3,
                'database': 'mysql',
                'instance_type': 't3.medium'
            },
            'ai_response': ai_response,
            'confidence': 0.95
        }
        
    except Exception as e:
        print(f"‚ùå AI failed: {e}")
        return {
            'status': 'fallback',
            'recommendations': {
                'memory': '2Gi',
                'cpu': '1000m',
                'replicas': 3,
                'database': 'mysql',
                'instance_type': 't3.medium'
            },
            'confidence': 0.85
        }

def generate_infrastructure_code(ai_result):
    """Generate Terraform code"""
    rec = ai_result.get('recommendations', {})
    
    terraform_config = f"""# Generated by Amazon Q AI Agent
# AI Confidence: {ai_result.get('confidence', 0.85)}

resource "aws_eks_cluster" "skyline" {{
  name     = "skyline-cluster"
  role_arn = aws_iam_role.eks_cluster.arn
  version  = "1.27"

  vpc_config {{
    subnet_ids = [aws_subnet.private[*].id]
  }}
}}

resource "aws_eks_node_group" "skyline" {{
  cluster_name    = aws_eks_cluster.skyline.name
  node_group_name = "skyline-nodes"
  node_role_arn   = aws_iam_role.eks_node_group.arn
  subnet_ids      = aws_subnet.private[*].id
  
  instance_types = ["{rec.get('instance_type', 't3.medium')}"]
  
  scaling_config {{
    desired_size = {rec.get('replicas', 3)}
    max_size     = {rec.get('replicas', 3) + 2}
    min_size     = 1
  }}
}}

resource "aws_rds_instance" "skyline" {{
  identifier = "skyline-db"
  engine     = "{rec.get('database', 'mysql')}"
  instance_class = "db.t3.micro"
  allocated_storage = 20
  
  db_name  = "skyline"
  username = "admin"
  password = "changeme123!"
  
  skip_final_snapshot = true
}}"""
    
    return {'terraform_config': terraform_config}

def generate_deployment_config(ai_result):
    """Generate K8s deployment"""
    rec = ai_result.get('recommendations', {})
    
    k8s_config = f"""# Generated by Amazon Q AI Agent
apiVersion: apps/v1
kind: Deployment
metadata:
  name: skyline-app
spec:
  replicas: {rec.get('replicas', 3)}
  selector:
    matchLabels:
      app: skyline-app
  template:
    metadata:
      labels:
        app: skyline-app
    spec:
      containers:
      - name: skyline-app
        image: skyline-app:latest
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "{rec.get('memory', '2Gi')}"
            cpu: "{rec.get('cpu', '1000m')}"
          limits:
            memory: "{rec.get('memory', '2Gi')}"
            cpu: "{rec.get('cpu', '1000m')}"
---
apiVersion: v1
kind: Service
metadata:
  name: skyline-service
spec:
  selector:
    app: skyline-app
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer"""
    
    return {'k8s_config': k8s_config}

def save_results_to_s3(repository, branch, commit, results):
    """Save to S3"""
    s3 = boto3.client('s3', region_name='ap-northeast-2')
    bucket_name = 'skyline-ai-results'
    
    try:
        key = f'{repository}/{branch}/{commit}/analysis.json'
        s3.put_object(
            Bucket=bucket_name,
            Key=key,
            Body=json.dumps(results, indent=2),
            ContentType='application/json'
        )
        print(f"‚úÖ Saved to S3: s3://{bucket_name}/{key}")
        return {'success': True, 'key': key}
    except Exception as e:
        print(f"‚ùå S3 save failed: {e}")
        return {'success': False, 'error': str(e)}

def create_github_pr_with_generated_files(repository, branch, commit, ai_result, infra_result, deploy_result):
    """Create GitHub PR with AI-generated files"""
    print("üîÑ Creating GitHub PR with generated files...")
    
    try:
        # GitHub API setup
        github_token = os.environ.get('GITHUB_TOKEN')
        if not github_token:
            print("‚ùå No GitHub token found")
            return {'success': False, 'error': 'No GitHub token'}
        
        headers = {
            'Authorization': f'token {github_token}',
            'Accept': 'application/vnd.github.v3+json'
        }
        
        # Create new branch
        branch_name = f"ai-generated-{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}"
        
        # Get base branch SHA
        base_url = f"https://api.github.com/repos/jongminoh-bsp/{repository}"
        ref_response = requests.get(f"{base_url}/git/refs/heads/{branch}", headers=headers)
        base_sha = ref_response.json()['object']['sha']
        
        # Create new branch
        requests.post(f"{base_url}/git/refs", 
            headers=headers,
            json={
                'ref': f'refs/heads/{branch_name}',
                'sha': base_sha
            }
        )
        
        # Create files
        files_to_create = [
            {
                'path': 'generated_terraform/main.tf',
                'content': infra_result['terraform_config'],
                'message': 'ü§ñ Add AI-generated Terraform configuration'
            },
            {
                'path': 'generated_k8s/deployment.yaml', 
                'content': deploy_result['k8s_config'],
                'message': 'ü§ñ Add AI-generated Kubernetes deployment'
            },
            {
                'path': 'ai_analysis_result.json',
                'content': json.dumps(ai_result, indent=2),
                'message': 'ü§ñ Add Amazon Q AI analysis results'
            }
        ]
        
        # Create each file
        for file_info in files_to_create:
            requests.put(f"{base_url}/contents/{file_info['path']}",
                headers=headers,
                json={
                    'message': file_info['message'],
                    'content': requests.utils.quote(file_info['content'].encode()).replace('%', ''),
                    'branch': branch_name
                }
            )
        
        # Create PR
        pr_response = requests.post(f"{base_url}/pulls",
            headers=headers,
            json={
                'title': f'ü§ñ Amazon Q AI Generated Infrastructure - {datetime.utcnow().strftime("%Y-%m-%d %H:%M")}',
                'head': branch_name,
                'base': branch,
                'body': f"""## ü§ñ Amazon Q AI Generated Infrastructure

**AI Analysis Results:**
- **Confidence**: {ai_result.get('confidence', 0.85) * 100:.1f}%
- **Memory**: {ai_result.get('recommendations', {}).get('memory', '2Gi')}
- **CPU**: {ai_result.get('recommendations', {}).get('cpu', '1000m')}
- **Replicas**: {ai_result.get('recommendations', {}).get('replicas', 3)}
- **Database**: {ai_result.get('recommendations', {}).get('database', 'mysql')}

**Generated Files:**
- `generated_terraform/main.tf` - EKS cluster and RDS configuration
- `generated_k8s/deployment.yaml` - Kubernetes deployment with AI recommendations
- `ai_analysis_result.json` - Complete AI analysis results

**Next Steps:**
1. Review the AI-generated configurations
2. Merge this PR to deploy infrastructure
3. Application will be deployed automatically

*Generated by Amazon Q AI Agent* üöÄ"""
            }
        )
        
        if pr_response.status_code == 201:
            pr_url = pr_response.json()['html_url']
            print(f"‚úÖ GitHub PR created: {pr_url}")
            return {'success': True, 'pr_url': pr_url}
        else:
            print(f"‚ùå PR creation failed: {pr_response.text}")
            return {'success': False, 'error': pr_response.text}
            
    except Exception as e:
        print(f"‚ùå GitHub PR creation failed: {e}")
        return {'success': False, 'error': str(e)}
