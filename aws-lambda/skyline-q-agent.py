import json
import boto3
import os
from datetime import datetime

def lambda_handler(event, context):
    """
    Amazon Q Agent Lambda Function
    Triggered by GitHub Actions to analyze Skyline app
    """
    
    print("ü§ñ Amazon Q Agent Lambda started")
    print(f"Event: {json.dumps(event, indent=2)}")
    
    # Extract event data
    repository = event.get('repository', 'KDT')
    branch = event.get('branch', 'dev')
    commit = event.get('commit', 'unknown')
    app_path = event.get('app_path', 'app/')
    
    try:
        # Step 1: Amazon Q AI Analysis
        ai_result = run_amazon_q_analysis(app_path)
        
        # Step 2: Generate Infrastructure Code
        infra_result = generate_infrastructure_code(ai_result)
        
        # Step 3: Generate Deployment Config
        deploy_result = generate_deployment_config(ai_result)
        
        # Step 4: Save results to S3
        save_results_to_s3(repository, branch, commit, {
            'ai_analysis': ai_result,
            'infrastructure': infra_result,
            'deployment': deploy_result,
            'status': 'completed',
            'timestamp': datetime.utcnow().isoformat()
        })
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'Amazon Q Agent completed successfully',
                'ai_analysis': ai_result,
                'infrastructure_generated': True,
                'deployment_config_ready': True,
                'next_steps': 'Check S3 bucket for generated files'
            })
        }
        
    except Exception as e:
        print(f"‚ùå Amazon Q Agent failed: {str(e)}")
        
        return {
            'statusCode': 500,
            'body': json.dumps({
                'message': 'Amazon Q Agent failed',
                'error': str(e)
            })
        }

def run_amazon_q_analysis(app_path):
    """Run Amazon Q AI analysis using Bedrock"""
    print("ü§ñ Running Amazon Q AI analysis...")
    
    bedrock = boto3.client('bedrock-runtime', region_name='ap-northeast-2')
    
    try:
        response = bedrock.invoke_model(
            modelId='anthropic.claude-3-haiku-20240307-v1:0',
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 300,
                "messages": [{
                    "role": "user",
                    "content": f"""Analyze the Skyline airline reservation system (Spring Boot application).
                    
                    Provide recommendations in JSON format:
                    {{
                        "memory": "2Gi",
                        "cpu": "1000m", 
                        "replicas": 3,
                        "database": "mysql",
                        "instance_type": "t3.medium",
                        "estimated_cost": 200
                    }}"""
                }]
            })
        )
        
        result = json.loads(response['body'].read())
        ai_response = result['content'][0]['text']
        
        print("üéâ Amazon Q AI Analysis Result:")
        print(ai_response)
        
        return {
            'status': 'success',
            'recommendations': ai_response,
            'confidence': 0.95,
            'ai_engine': 'amazon-bedrock-claude-seoul'
        }
        
    except Exception as e:
        print(f"‚ùå AI analysis failed: {e}")
        
        # Fallback recommendations
        return {
            'status': 'fallback',
            'recommendations': {
                'memory': '2Gi',
                'cpu': '1000m',
                'replicas': 3,
                'database': 'mysql',
                'instance_type': 't3.medium',
                'estimated_cost': 200
            },
            'confidence': 0.85,
            'ai_engine': 'fallback-config'
        }

def generate_infrastructure_code(ai_result):
    """Generate Terraform code based on AI recommendations"""
    print("üèóÔ∏è Generating infrastructure code...")
    
    recommendations = ai_result.get('recommendations', {})
    
    # Generate Terraform configuration
    terraform_config = f"""
# Generated by Amazon Q AI Agent
# Recommendations: {json.dumps(recommendations, indent=2)}

resource "aws_eks_cluster" "skyline" {{
  name     = "skyline-cluster"
  role_arn = aws_iam_role.eks_cluster.arn
  version  = "1.27"

  vpc_config {{
    subnet_ids = [aws_subnet.private[*].id]
  }}
}}

resource "aws_eks_node_group" "skyline" {{
  cluster_name    = aws_eks_cluster.skyline.name
  node_group_name = "skyline-nodes"
  node_role_arn   = aws_iam_role.eks_node_group.arn
  subnet_ids      = aws_subnet.private[*].id
  
  instance_types = ["{recommendations.get('instance_type', 't3.medium')}"]
  
  scaling_config {{
    desired_size = {recommendations.get('replicas', 3)}
    max_size     = {recommendations.get('replicas', 3) + 2}
    min_size     = 1
  }}
}}

resource "aws_rds_instance" "skyline" {{
  identifier = "skyline-db"
  engine     = "{recommendations.get('database', 'mysql')}"
  instance_class = "db.t3.micro"
  allocated_storage = 20
  
  db_name  = "skyline"
  username = "admin"
  password = "changeme123!"
  
  skip_final_snapshot = true
}}
"""
    
    return {
        'status': 'generated',
        'terraform_config': terraform_config,
        'ai_optimized': True
    }

def generate_deployment_config(ai_result):
    """Generate Kubernetes deployment config"""
    print("üöÄ Generating deployment configuration...")
    
    recommendations = ai_result.get('recommendations', {})
    
    k8s_config = f"""
# Generated by Amazon Q AI Agent
apiVersion: apps/v1
kind: Deployment
metadata:
  name: skyline-app
spec:
  replicas: {recommendations.get('replicas', 3)}
  selector:
    matchLabels:
      app: skyline-app
  template:
    metadata:
      labels:
        app: skyline-app
    spec:
      containers:
      - name: skyline-app
        image: skyline-app:latest
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "{recommendations.get('memory', '2Gi')}"
            cpu: "{recommendations.get('cpu', '1000m')}"
          limits:
            memory: "{recommendations.get('memory', '2Gi')}"
            cpu: "{recommendations.get('cpu', '1000m')}"
---
apiVersion: v1
kind: Service
metadata:
  name: skyline-service
spec:
  selector:
    app: skyline-app
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer
"""
    
    return {
        'status': 'generated',
        'k8s_config': k8s_config,
        'ai_optimized': True
    }

def save_results_to_s3(repository, branch, commit, results):
    """Save analysis results to S3"""
    s3 = boto3.client('s3', region_name='ap-northeast-2')
    bucket_name = 'skyline-ai-results'  # Create this bucket
    
    try:
        # Save analysis results
        key = f'{repository}/{branch}/{commit}/analysis.json'
        s3.put_object(
            Bucket=bucket_name,
            Key=key,
            Body=json.dumps(results, indent=2),
            ContentType='application/json'
        )
        
        # Save Terraform config
        if 'infrastructure' in results:
            terraform_key = f'{repository}/{branch}/{commit}/terraform/main.tf'
            s3.put_object(
                Bucket=bucket_name,
                Key=terraform_key,
                Body=results['infrastructure']['terraform_config'],
                ContentType='text/plain'
            )
        
        # Save K8s config
        if 'deployment' in results:
            k8s_key = f'{repository}/{branch}/{commit}/k8s/deployment.yaml'
            s3.put_object(
                Bucket=bucket_name,
                Key=k8s_key,
                Body=results['deployment']['k8s_config'],
                ContentType='text/yaml'
            )
        
        print(f"‚úÖ Results saved to S3: s3://{bucket_name}/{key}")
        
    except Exception as e:
        print(f"‚ùå Failed to save to S3: {e}")
        # Continue without failing
